{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import utils\n",
    "\n",
    "from text_classification.config import Config\n",
    "from text_classification.network import get_model\n",
    "from text_classification.preprocessing import text_preprocessing, generate_embedding_matrix, load_word_embedding_matrix\n",
    "\n",
    "folder_path = \"D:\\\\deep_learning_experiments\"\n",
    "lankadeepa_data_path = folder_path + \"\\\\sinhala_data\\\\lankadeepa_tagged_comments.csv\"\n",
    "gossip_lanka_data_path = folder_path + \"\\\\sinhala_data\\\\gossip_lanka_tagged_comments.csv\"\n",
    "\n",
    "word_embedding_keyed_vectors_path = 'D:\\\\deep_learning_experiments\\\\word_vectors_sinhala\\\\keyed.kv'\n",
    "word_embedding_matrix_path = 'D:\\\\deep_learning_experiments\\\\word_embedding_matrix'\n",
    "EMBEDDING_SIZE = 300\n",
    "\n",
    "lankadeepa_data = pd.read_csv(lankadeepa_data_path)[:9059]\n",
    "gossipLanka_data = pd.read_csv(gossip_lanka_data_path)\n",
    "gossipLanka_data = gossipLanka_data.drop(columns=['Unnamed: 3'])\n",
    "\n",
    "word_embedding_path = folder_path\n",
    "\n",
    "all_data = pd.concat([lankadeepa_data, gossipLanka_data], ignore_index=True)\n",
    "all_data['label'] = all_data['label'] - 2\n",
    "print(all_data)\n",
    "\n",
    "comments_text, labels = text_preprocessing(all_data)\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(comments_text)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "print(vocab_size)\n",
    "\n",
    "encoded_docs = t.texts_to_sequences(comments_text)\n",
    "max_length = 30\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "comment_labels = np.array(labels)\n",
    "comment_labels = utils.to_categorical(comment_labels)\n",
    "padded_docs = np.array(padded_docs)\n",
    "\n",
    "print(\"Shape of all comments: \", padded_docs.shape)\n",
    "print(\"Shape of labels: \", comment_labels.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_docs, comment_labels, test_size=0.1, random_state=42,\n",
    "                                                    shuffle=True)\n",
    "print(\"Train lables shape: \", y_train.shape)\n",
    "\n",
    "# generate embedding matrix\n",
    "# embedding_matrix = generate_embedding_matrix(word_embedding_keyed_vectors_path, word_embedding_matrix_path, vocab_size,\n",
    "#                                              EMBEDDING_SIZE, t)\n",
    "\n",
    "# load embedding matrix\n",
    "embedding_matrix = load_word_embedding_matrix(word_embedding_matrix_path)\n",
    "\n",
    "# print(embedding_matrix[1])\n",
    "config = Config(\n",
    "    seq_len=max_length,\n",
    "    num_classes=4,\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_size=EMBEDDING_SIZE,\n",
    "    dropout_rate=0.8,\n",
    "    x_train=X_train,\n",
    "    y_train=y_train,\n",
    "    x_test=X_test,\n",
    "    y_test=y_test,\n",
    "    pretrain_vec=embedding_matrix)\n",
    "\n",
    "model = get_model(config)\n",
    "model.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}